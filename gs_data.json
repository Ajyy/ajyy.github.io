{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "eUiG0O0AAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Junyi Ao", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=eUiG0O0AAAAJ&citpid=5", "affiliation": "The Chinese University of Hong Kong, Shenzhen", "interests": ["Speech Recognition", "Self-Supervised Learning"], "email_domain": "@link.cuhk.edu.cn", "homepage": "https://ajyy.github.io/", "citedby": 565, "publications": {"eUiG0O0AAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing", "pub_year": "2022"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:d1gkVwhDpl0C", "num_citations": 288, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5341736616533210721", "cites_id": ["5341736616533210721"]}, "eUiG0O0AAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "LightHuBERT: Lightweight and Configurable Speech Representation Learning with Once-for-All Hidden-Unit BERT", "pub_year": "2022"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:9yKSN-GCB0IC", "num_citations": 68, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5537527528769427293", "cites_id": ["5537527528769427293"]}, "eUiG0O0AAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SpeechUT: Bridging Speech and Text with Hidden-Unit for Encoder-Decoder Based Speech-Text Pre-training", "pub_year": "2022"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:IjCSPb-OGe4C", "num_citations": 60, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8963519551547997493", "cites_id": ["8963519551547997493"]}, "eUiG0O0AAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-View Self-Attention Based Transformer for Speaker Recognition", "pub_year": "2022"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:u-x6o8ySG0sC", "num_citations": 51, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3535805686887714253", "cites_id": ["3535805686887714253"]}, "eUiG0O0AAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words", "pub_year": "2024"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:WF5omc3nYNoC", "num_citations": 28, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6093497436504891285", "cites_id": ["6093497436504891285"]}, "eUiG0O0AAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Pre-Training Transformer Decoder for End-to-End ASR Model with Unpaired Speech Data", "pub_year": "2022"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:2osOgNQ5qMEC", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4320760502099413219", "cites_id": ["4320760502099413219"]}, "eUiG0O0AAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The YiTrans End-to-End Speech Translation System for IWSLT 2022 Offline Shared Task", "pub_year": "2022"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:qjMakFHDy7sC", "num_citations": 11, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7959611725284860043", "cites_id": ["7959611725284860043"]}, "eUiG0O0AAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "token2vec: A Joint Self-Supervised Pre-training Framework Using Unpaired Speech and Text", "pub_year": "2023"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:Tyk-4Ss8FVUC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11469090494285339901", "cites_id": ["11469090494285339901"]}, "eUiG0O0AAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CoBERT: Self-Supervised Speech Representation Learning Through Code Representation Learning", "pub_year": "2022"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:zYLM7Y9cAGgC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7187623269730052331", "cites_id": ["7187623269730052331"]}, "eUiG0O0AAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "USED: Universal Speaker Extraction and Diarization", "pub_year": "2023"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:W7OEmFMy1HYC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4876723401393226948", "cites_id": ["4876723401393226948"]}, "eUiG0O0AAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Self-Supervised Acoustic Word Embedding Learning via Correspondence Transformer Encoder", "pub_year": "2023"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:Y0pCki6q_DkC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3877272481799478385", "cites_id": ["3877272481799478385"]}, "eUiG0O0AAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SA-WavLM: Speaker-Aware Self-Supervised Pre-training for Mixture Speech", "pub_year": "2024"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:ufrVoPGSRksC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17032824022803890824", "cites_id": ["17032824022803890824"]}, "eUiG0O0AAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Overview of the Amphion Toolkit (v0. 2)", "pub_year": "2025"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:LkGwnXOMwfcC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17484643500059740253", "cites_id": ["17484643500059740253"]}, "eUiG0O0AAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Text-guided HuBERT: Self-Supervised Speech Pre-training via Generative Adversarial Networks", "pub_year": "2024"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:YsMSGLbcyi4C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1517463953865296056", "cites_id": ["1517463953865296056"]}, "eUiG0O0AAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Improving Attention-based End-to-end ASR by Incorporating an N-gram Neural Network", "pub_year": "2021"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:u5HHmVD_uO8C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12485951423980144126", "cites_id": ["12485951423980144126"]}, "eUiG0O0AAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Solla: Towards a Speech-Oriented LLM That Hears Acoustic Context", "pub_year": "2025"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:roLk4NBRz8UC", "num_citations": 0}, "eUiG0O0AAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The NUS-HLT System for ICASSP2024 ICMC-ASR Grand Challenge", "pub_year": "2023"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:eQOLeE2rZwMC", "num_citations": 0}, "eUiG0O0AAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The YiTrans speech translation system for IWSLT 2022 offline shared task", "pub_year": "2022"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:UeHWp8X0CEIC", "num_citations": 0}, "eUiG0O0AAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sounding the Alarm: Backdooring Acoustic Foundation Models for Physically Realizable Triggers"}, "filled": false, "author_pub_id": "eUiG0O0AAAAJ:_FxGoFyzp5QC", "num_citations": 0}}, "citedby5y": 563, "hindex": 9, "hindex5y": 9, "i10index": 8, "i10index5y": 8, "cites_per_year": {"2022": 61, "2023": 181, "2024": 222, "2025": 96}, "updated": "2025-06-29 08:06:10.884915"}